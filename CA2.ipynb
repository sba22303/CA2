{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a50d5ff",
   "metadata": {},
   "source": [
    "## CA2 ##\n",
    "## IRELAND MEAT PRODUCTION / CAP PERFORMANCE COMPARED TO OTHER COUNTRIES\n",
    "\n",
    "1. Step 1 : Exploratory Data Analysis\n",
    "2. Step 2 : Statistics\n",
    "3. Step 3 : ML Model around our data\n",
    "4. Step 4 : Optimization with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed196244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import of library for exploration of data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We can suppress the warnings for a better reading\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fa656c",
   "metadata": {},
   "source": [
    "# 1. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deebb58a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'faostat/irl_fr_sp_usa.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Source data generated from the link below\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#https://www.fao.org/faostat/en/#data/QV\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#Read files from Faostat\u001b[39;00m\n\u001b[0;32m      9\u001b[0m ag_production_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfaostat/irl_fr_sp_usa.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 10\u001b[0m ag_prod_value_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag_production_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#Quick Overview of the data\u001b[39;00m\n\u001b[0;32m     13\u001b[0m ag_prod_value_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'faostat/irl_fr_sp_usa.csv'"
     ]
    }
   ],
   "source": [
    "#Source data generated from the link below\n",
    "#https://www.fao.org/faostat/en/#data/QV\n",
    "\n",
    "# Applied filter\n",
    "# Country = Ireland,France,Spain,USA Year Only last 3 years including 2018,2019,2020 (2021,2022 data are not available yet)\n",
    "\n",
    "#Read files from Faostat\n",
    "\n",
    "ag_production_value = \"faostat/irl_fr_sp_usa.csv\"\n",
    "ag_prod_value_df = pd.read_csv(ag_production_value)\n",
    "\n",
    "#Quick Overview of the data\n",
    "ag_prod_value_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca511d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_prod_value_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02569977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#View rows and column count\n",
    "ag_prod_value_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdd0537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check columns name if there is any irrelevant spelling\n",
    "ag_prod_value_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27523a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardisation of column name -> Rename column name to keep a single uppercase to make easier our work with analysis. \n",
    "ag_prod_value_df.rename(columns = {\"Domain Code\" :\"Domain_code\", \n",
    "                                  \"Domain\": \"Domain\",\n",
    "                                  \"Area Code (M49)\":\"Area_code_m49\",\n",
    "                                  \"Area\":\"Area\",\n",
    "                                  \"Element Code\":\"Element_code\",\n",
    "                                  \"Element\": \"Element\",\n",
    "                                  \"Item Code (CPC)\":\"Item_code_cpc\",\n",
    "                                  \"Item\":\"Item\",\n",
    "                                  \"Year Code\":\"Year_code\",\n",
    "                                  \"Year\":\"Year\",\n",
    "                                    \"Unit\": \"Unit\",\n",
    "                                    \"Value\":\"Value\",\n",
    "                                    \"Flag\":\"Flag\",\n",
    "                                    \"Flag Description\" : \"Flag_description\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301e32e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's view Unique Value in axes 0 -> In each Column\n",
    "ag_prod_value_df.nunique(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627afdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing column having a single value as these one wont help us to much for our analysis\n",
    "#These columns are : Domain_code, Domain, Flag, Flag_description\n",
    "#First lets see differenet values that they contain\n",
    "\n",
    "print(\"##### Domain_code: #####\")\n",
    "print(pd.unique(ag_prod_value_df['Domain_code']))\n",
    "print(\"\\n##### Domain : #####\")\n",
    "print(pd.unique(ag_prod_value_df['Domain']))\n",
    "print(\"\\n##### Area_code_m49 : #####\")\n",
    "print(pd.unique(ag_prod_value_df['Area_code_m49']))\n",
    "\n",
    "print(\"##### Area: #####\")\n",
    "print(pd.unique(ag_prod_value_df['Area']))\n",
    "print(\"\\n##### Flag : #####\")\n",
    "print(pd.unique(ag_prod_value_df['Flag']))\n",
    "print(\"\\n##### Flag_descritpion : #####\")\n",
    "print(pd.unique(ag_prod_value_df['Flag_description']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6768821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removal of columns\n",
    "ag_prod_value_df = ag_prod_value_df.drop(['Domain_code','Domain','Flag','Flag_description'], axis=1)\n",
    "\n",
    "#View after Removal\n",
    "ag_prod_value_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b18507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check also the value in Element and Element_code\n",
    "print(\"\\n##### Element : #####\")\n",
    "print(pd.unique(ag_prod_value_df['Element']))\n",
    "print(\"\\n##### Element_code : #####\")\n",
    "print(pd.unique(ag_prod_value_df['Element_code']))\n",
    "print(\"\\n##### Unit : #####\")\n",
    "print(pd.unique(ag_prod_value_df['Unit']))\n",
    "\n",
    "\n",
    "# Definitions and standards used in FAOSTAT \n",
    "# I$ = international dollar\n",
    "# SLC = standard local currency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eddd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For simplification purpose we consider that the Unit is the US dollar, and SLC for Ireland/France/Spain is 1 Euro = 1 Dollar.\n",
    "## Lets Remove unnecessary Column: Element, Element_code, Year_code\n",
    "ag_prod_value_df = ag_prod_value_df.drop(['Element','Element_code','Year_code'], axis=1)\n",
    "ag_prod_value_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7c288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check values in Item\n",
    "print(\"\\n##### Item : #####\")\n",
    "print(pd.unique(ag_prod_value_df['Item']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fc1301",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We will focus on Meat and Milk Production value \n",
    "## lets simplify our dataframe creating a new one containing only meat and milk data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2627b473",
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_milk_df = ag_prod_value_df.loc[(ag_prod_value_df['Item'].str.contains('Meat'))|(ag_prod_value_df['Item'].str.contains('meat'))|(ag_prod_value_df['Item'].str.contains('milk'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227b7262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick Overview of the dataframe\n",
    "meat_milk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b051a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_milk_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0af97aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check that we have all values in which we are focusing\n",
    "## Check values in Item\n",
    "print(\"\\n##### Item : #####\")\n",
    "print(pd.unique(meat_milk_df['Item']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42723782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More Interesting to categories and classify these creating 3 new columns\n",
    "# Category Column -> To Classify by type MEAT or MILK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d0c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Category Column\n",
    "meat_milk_df['Category'] = np.where(meat_milk_df['Item'].str.contains('milk'),'MILK','MEAT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfba58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick Overview\n",
    "meat_milk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81ecce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Animal Column\n",
    "conditions = [meat_milk_df['Item'].str.contains('Horse'), \n",
    "              meat_milk_df['Item'].str.contains('cattle'),\n",
    "             meat_milk_df['Item'].str.contains('chickens'),\n",
    "              meat_milk_df['Item'].str.contains('ducks'),  \n",
    "              meat_milk_df['Item'].str.contains('geese'),\n",
    "              meat_milk_df['Item'].str.contains('goat'),\n",
    "             meat_milk_df['Item'].str.contains('pig'),\n",
    "              meat_milk_df['Item'].str.contains('rabbits'), \n",
    "             meat_milk_df['Item'].str.contains('sheep'),\n",
    "             meat_milk_df['Item'].str.contains('turkeys'),\n",
    "              meat_milk_df['Item'].str.contains('goats'),\n",
    "              meat_milk_df['Item'].str.contains('Game')]\n",
    "\n",
    "choices = ['Horse','Cattle','Chicken','Duck', 'Geese','Goat','Pig','Rabbit', 'Sheep', 'Turkey','Goat','Game']\n",
    "meat_milk_df['Animal'] = np.select(conditions,choices,default=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cc1ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_milk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db2ed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remind quickly available values\n",
    "pd.unique(meat_milk_df['Animal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2171a03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Animal_group column to classify the production of meat.\n",
    "# CATTLE(cattle only), POULTRY(chickens, ducks, geese, rabbits, turkey), SHEEP(sheep), OTHER(Horse, Game, Pig)\n",
    "\n",
    "animal_group_dictionnary = {'Horse':'Other', 'Cattle':'Cattle', 'Chicken':'Poultry', \n",
    "                            'Duck':'Poultry', 'Geese':'Poultry', 'Goat':'Sheep', 'Pig':'Other',\n",
    "                            'Rabbit':'Poultry', 'Sheep':'Sheep', 'Turkey':'Poultry', 'Game':'Other' }\n",
    "\n",
    "meat_milk_df['Animal_group'] = meat_milk_df['Animal'].map(animal_group_dictionnary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5c2b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick check of new DF\n",
    "meat_milk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e786ac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Review of result \n",
    "pd.unique(meat_milk_df['Animal_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb1baa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if we need to remove rows with nan values \n",
    "print(meat_milk_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a577156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Last Check to view if we are ready to plot all these and start our analysis\n",
    "meat_milk_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db707b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the shape of the DF\n",
    "meat_milk_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e445285",
   "metadata": {},
   "source": [
    "### Our Conclusion : \n",
    "Our Dataframe doenst contain any null value, and is ready to be plotted and we can start our work around."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9935baa2",
   "metadata": {},
   "source": [
    "## Visualization of our dataframe for Ireland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfaa07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering for Ireland only\n",
    "ir_mm_df = meat_milk_df.loc[meat_milk_df['Area']=='Ireland']\n",
    "ir_mm_df = ir_mm_df.groupby(['Year','Animal', 'Animal_group', 'Category'], as_index=False)[['Value']].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be600e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(meat_milk_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233d796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ir_mm_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c8df60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import interactive Altair library\n",
    "import altair as alt\n",
    "\n",
    "# First Overview of the Interactive View for Ireland\n",
    "alt.Chart(ir_mm_df).mark_point().encode(\n",
    "    alt.X('Animal'),\n",
    "    alt.Y('Value'),\n",
    "    tooltip=['Animal', 'Category', 'Value', 'Year']\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=300\n",
    ").configure_point(\n",
    "    size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454b960a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Interactive Visualization\n",
    "# Visualization for different Year -> Production Value by Animal\n",
    "\n",
    "select_country = alt.selection_single(\n",
    "    name='select', fields=['Year'], init={'Year': '2018'},\n",
    "    bind=alt.binding_range(min=2018, max=2020, step=1)\n",
    ")\n",
    "alt.Chart(ir_mm_df).mark_point(filled=True).encode(\n",
    "    alt.X('Animal', scale=alt.Scale(zero=False)),\n",
    "    alt.Y('Value', scale=alt.Scale(zero=False)),\n",
    "    tooltip=['Animal', 'Category', 'Value', 'Year'],\n",
    "    color='Category',\n",
    "    \n",
    ").add_selection(select_country).transform_filter(select_country).properties(\n",
    "    width=600,\n",
    "    height=300,\n",
    "    title = 'Ireland Meat Milk Production Value From 2018 to 2020'\n",
    ").configure_point(\n",
    "    size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04d0f0b",
   "metadata": {},
   "source": [
    "## Our Conclusion :\n",
    "We can remark that cattle production value is the highest type, followed by pig and sheep in the last 3 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9842096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47bbba13",
   "metadata": {},
   "source": [
    "## 2 - STATISTICS -> CAP PERFORMANCE ON MEAT MILK PRODUCTION VALUE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad63835",
   "metadata": {},
   "source": [
    "For simplification purpose we will study the performance on the last 3 years available in our dataframe those are 2020,2019,2018. We will compare our performance with other top 2 countries of EU in the agriculture production (France, Spain). We will use data provided by the agridata website. The CAP provide income support for farmers in each EU member country. The Income Support Amount is calculated as follow : \n",
    "Number of CAP beneficiary (for the Year) multiply Amount per CAP beneficary (for the Year).\n",
    "\n",
    "I see that in the public website we dont have appropriate dataset, all dataset are bulked with too much unnecessary data for our analysis. I build the dataframe manually as it will save time and coding lines.\n",
    "\n",
    "The source of these numbers are from the visual dashboard of agridata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d25008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets built the cap_df dataframe first according to the value provided by agridata website.\n",
    "# Data is as follow :\n",
    "# 2018, EU, 6158770, 6480 - France, 325810, 22990 - Ireland, 123300, 10330 - Spain, 663190, 7460\n",
    "# 2019, EU, 6064820, 6610 - France, 321110, 23370 - Ireland, 122580, 10540 - Spain, 654400, 7620\n",
    "# 2020, EU, 5996360, 6620 - France, 316120, 23400 - Ireland, 122450, 10540 - spain, 644500, 7590\n",
    "\n",
    "\n",
    "cap_df = pd.DataFrame(\n",
    "    \n",
    "    {\n",
    "    'Year' : [2018,2018,2018,2018,2019,2019,2019,2019,2020,2020,2020,2020], \n",
    "    'Entity':['EU', 'France', 'Ireland', 'Spain','EU', 'France', 'Ireland', 'Spain', 'EU', 'France', 'Ireland', 'Spain'],\n",
    "    'Beneficiary_number' : [6158770,325810,123300,663190,6064820,321110,122580,654400,5996360,316120,122450,644500],\n",
    "    'Amount_per_beneficiary' : [6480,22990,10330,7460,6610,23370,10540,7620,6620,23400,10540,7590],\n",
    "    }\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551a1cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick Overview\n",
    "cap_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71e3e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick Overview\n",
    "cap_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7933c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_df['Total_amount'] = cap_df['Amount_per_beneficiary']*cap_df['Beneficiary_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72b9c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4550f6",
   "metadata": {},
   "source": [
    "Our Conclusion : We have now our cap_df dataframe that contains values for the last 3 years regarding CAP for Ireland, France, Spain, the specific amount of Farming Income Support that have been paid for each country. For our analysis i have also included the total paid by EU for those specific years in order to have a global overview of the impact of the CAP support plan. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ddb593",
   "metadata": {},
   "source": [
    "### Descriptive Statistics\n",
    "As a reminder we are in the situation where we have the production value for Ireland, Spain, France for last 3 years.\n",
    "We have the CAP support amount for each for these countries and for the last 3 years.\n",
    "We can now start to analyse the production value behaviour and see the impact of the CAP on a specific agriculture, here is for Meat and Milk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0592a6d8",
   "metadata": {},
   "source": [
    "1. Ireland production value of meat/milk on the last 3 years.\n",
    "2. Central Tendancy : Mean, Mo, Median. \n",
    "3. Variation Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b262fd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reminder of what we have as in our Meat/Milk production value for Ireland in our dataframe.\n",
    "ir_mm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22dad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate per Year the Value of the Meat/Milk Production \n",
    "ir_mm_df = ir_mm_df.groupby(\"Year\").sum()\n",
    "ir_mm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265c229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's calculate our Mean, Median, Variance and deviation for Meat/Milk Values.\n",
    "ir_mm_mean = ir_mm_df['Value'].mean()\n",
    "print(\"## The Mean for Meat Milk Production Value is : \", ir_mm_mean)\n",
    "print(\"## The Median for Meat Milk Production Value is : \",ir_mm_df['Value'].median())\n",
    "print(\"## The Variance for Meat Milk production Value is :\",ir_mm_df['Value'].var())\n",
    "ir_mm_var = ir_mm_df['Value'].var()\n",
    "ir_mm_deviation =math.sqrt(ir_mm_var)\n",
    "print(\"## The Deviation for Meat Milk Production Value is :\",ir_mm_deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90779359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's plot Ireland Meat/Milk Production Value for the last 3 Years\n",
    "import plotly.express as px\n",
    "px.box(ir_mm_df, y='Value', width=600, height=800, title='Ireland Meat/Milk Production Value Last 3 years')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82767f6",
   "metadata": {},
   "source": [
    "### Inferential Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd47030",
   "metadata": {},
   "source": [
    "If we look the performance of Ireland in Meat/Milk production value for the last 3 years we have a constant increase in the production value. With the standard deviation that we have calculated before we can see that this value increase in linear way with a standard deviation at : \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbdc9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the last 3 years \n",
    "ir_mm_deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8292afe5",
   "metadata": {},
   "source": [
    "As a reminder the cap value distributed by country in EU between France, Spain, Ireland is as follow :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920a7d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick Overview\n",
    "cap_df.head(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1d0e5e",
   "metadata": {},
   "source": [
    "If we look number recorded in this dataframe we see that the Amount_per_beneficiary has increased from 2018 by 210,00 euros\n",
    "(2% of its initial value of 2018) and has not changed since 2019, and has the same amount in 2020. But we can notice that number of Beneficiary has decreased from 123300 to 122450. \n",
    "This has not prevent Ireland to increase his production value for Meat/Milk this is an interesting scenario.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06520842",
   "metadata": {},
   "source": [
    "Our Conclusion : It seems that our Beneficiary amount has probably attained his optimal value to get the best performance in irish market.  Is this the case lets check this with Hypothetique Test. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d2c808",
   "metadata": {},
   "source": [
    "#### Hypothesis Test ## T-Test One Population\n",
    "Are we able to keep the production value for Ireland increasing with the same deviation for the coming years, and say that the performance of Cap value per beneficiary will enable Ireland to increase his production in Meat/milk for coming next three years, if we keep the same amount allocated per beneficiary, assuming that the number of beneficiary has been now stabilized and the change in coming 3 years will not be significant.\n",
    "\n",
    "Following values are known :\n",
    "\n",
    "1. σ Standard Deviation of Production Value Meat/Milk for Ireland -> ir_mm_deviation = 1092384\n",
    "2. n as number of sample data we have in this dataset  -> 3\n",
    "3. x̅ as the mean for the las 3 years for Ireland -> ir_mm_mean = 50721621 \n",
    "4. α signifiance at 5% \n",
    "\n",
    "Our Scenario :\n",
    "1. -> H0 -> Is the scenario where u = 50721621\n",
    "2. -> H1 -> Is the scenario where u =! 50721621\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d91700",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the library\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Define the variable \n",
    "X = ir_mm_df['Value']; X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a63ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#H0 : u = 50721621\n",
    "#H1 : u =! 50721621\n",
    "#stats.ttest_1samp(X,mu of H0)\n",
    "stats.ttest_1samp(X,ir_mm_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7a2062",
   "metadata": {},
   "source": [
    "#### Our Conclusion : \n",
    "We obtain a t-statistics value equal to zero, this means for us that our data match the H0 hypothesis, with a p-value as probability equal to 1. Probability to obtain the Meat/Milk production value at it average is very High we can keep then our Hypothesis of H0 as true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e84826b",
   "metadata": {},
   "source": [
    "#### Confidence Interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3682e2",
   "metadata": {},
   "source": [
    "Calculation of the Confidence Interval as a reminder with following values :\n",
    "1. Number of sample data we have in this dataset  -> 3\n",
    "2. x̅ as the mean for the las 3 years for Ireland -> ir_mm_mean = 50721621 \n",
    "3. We will use a confidence level at 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217b47f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's firts calculate the degre of freedom which is sample size -1\n",
    "degree_of_freedom = len(ir_mm_df['Value']) -1\n",
    "degree_of_freedom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e76d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import standard error library\n",
    "from scipy.stats import sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9f433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the standard error\n",
    "standard_error = sem(ir_mm_df['Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010762ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We set the confidence level\n",
    "confidence_level = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6dd09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import t library \n",
    "from scipy.stats import t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfbbf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calulating our Confidence Interval\n",
    "t.interval(confidence_level, degree_of_freedom, loc=ir_mm_mean, scale=standard_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438eb47d",
   "metadata": {},
   "source": [
    "#### Our Conclusion : \n",
    "Our Confidence interval has been calculated and we obtained an upper value of 53435255 and a lower value of 48007987. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf3e4d1",
   "metadata": {},
   "source": [
    "### Other country performance against Ireland"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400446f7",
   "metadata": {},
   "source": [
    "Ireland, France, Spain are all members of EU and receive different amount of CAP. The CAP is mainly an income support for farmers. If we look only at revenue production of these countries to measure their performance we will not get accurate analysis aligned with the reality.\n",
    "\n",
    "This is why i'm adding this CAP coefficent in our study. \n",
    "I've defined this coefficient number = Total_amount(for Year n for specific country) / Total_amount(for Year n for Total EU)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c542a8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick Overview\n",
    "cap_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511d7b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Adding Cap_coefficient column\n",
    "for ind, row in cap_df.iterrows():\n",
    "    if(cap_df.loc[ind, 'Entity'] == 'EU'): \n",
    "        cap_df.loc[ind, 'Cap_coefficient'] = 1\n",
    "        eu_amount = cap_df.loc[ind, 'Total_amount']\n",
    "    else:\n",
    "        current_year = cap_df.loc[ind, 'Year']    \n",
    "        cap_df.loc[ind, 'Cap_coefficient'] = row['Total_amount']/eu_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8264c3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69474b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering for Ireland/France/Spain only from meat_milk \n",
    "eu_mm_df = meat_milk_df.loc[(meat_milk_df['Area']=='Ireland')|(meat_milk_df['Area']=='Spain')|(meat_milk_df['Area']=='France')]\n",
    "eu_mm_df = eu_mm_df.groupby(['Year','Area','Animal', 'Animal_group', 'Category'], as_index=False)[['Value']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c0ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_mm_df.rename(columns = {\"Value\" :\"Production_value\", \"Area\" : \"Entity\"}, inplace = True)\n",
    "eu_mm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a670515",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping data rows\n",
    "eu_performance_df = eu_mm_df.groupby(['Year','Entity'], as_index=False)[['Production_value']].sum()\n",
    "eu_performance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3058f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging cap_df et eu_performance_df dataframe\n",
    "cap_df = cap_df.merge(eu_performance_df, on=['Year','Entity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3c8761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick Overview\n",
    "cap_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91bf3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normality Check of the data. Our variable is \"Production_value\"\n",
    "stats.probplot(cap_df.Production_value, plot=plt)\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8c2515",
   "metadata": {},
   "source": [
    "Our Conclusion : We can see clearly that our data are normally distributed between each other making almost a line for each country."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf62f5fa",
   "metadata": {},
   "source": [
    "### Shapiro wilk Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9deed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shapiro wilk test\n",
    "stats.shapiro(cap_df.Production_value[cap_df.Entity == \"France\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca4ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shapiro wilk test\n",
    "stats.shapiro(cap_df.Production_value[cap_df.Entity == \"Spain\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c5fcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shapiro wilk test\n",
    "stats.shapiro(cap_df.Production_value[cap_df.Entity == \"Ireland\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d7d7d5",
   "metadata": {},
   "source": [
    "Our Conclusion : Pvalue are greater than 0.05 for all countries, Shapiro Wilk Test confirm the normal distribution of our data and confirm the result of the graph that we obtained above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8e617b",
   "metadata": {},
   "source": [
    "### Standard Deviation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ef7f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation for France/Ireland/Spain\n",
    "france = cap_df.Production_value[cap_df.Entity == \"France\"]\n",
    "ireland = cap_df.Production_value[cap_df.Entity == \"Ireland\"]\n",
    "spain = cap_df.Production_value[cap_df.Entity == \"Spain\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485e2c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Standard Deviation for France is :\", france.std(),\"for Ireland is :\", ireland.std(), \"for Spain is :\", spain.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afac08a",
   "metadata": {},
   "source": [
    "Our Conclusion : The standard deviation is the highest for Spain and lowest for France."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bcdd8b",
   "metadata": {},
   "source": [
    "### Test of Homogeneity of Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aba1094",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Homogeneity of variance: Levene's test\n",
    "from scipy.stats import levene\n",
    "levene(france, spain, ireland, center = 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fde8013",
   "metadata": {},
   "source": [
    "Our Conclusion : We obtain a pvalue greater than 0.05 Levene test is non significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdf6933",
   "metadata": {},
   "source": [
    "### One-way ANOVA ( Analysis of Variance between 2 or more groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7b26d1",
   "metadata": {},
   "source": [
    "Analyzing variance between 3 groups France, Spain, Ireland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c0b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONE-WAY ANOVA\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "\n",
    "model = ols('Production_value~Entity', data = cap_df).fit()\n",
    "aov = sm.stats.anova_lm(model, type=2)\n",
    "print(aov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2326620",
   "metadata": {},
   "source": [
    "\n",
    "p<0,05 There are significant difference between entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b80f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANOVA TWO WAYS\n",
    "model2 = ols('Production_value~Entity+Cap_coefficient', data = cap_df).fit()\n",
    "aov2 = sm.stats.anova_lm(model2, type=2)\n",
    "print(aov2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d230da",
   "metadata": {},
   "source": [
    "## 3 - ML ON CAP PERFORMANCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ce1105",
   "metadata": {},
   "source": [
    "Supervised ML - based on CRISP-DM - Business Case/Need\n",
    "We try to see if we can predict the best cap coefficent that will enable a country of EU to perform better in the agriculture production value specifically for meat/milk. As we are looking for a number and/or a classification, Supervised ML is the most appropriate methodology.\n",
    "\n",
    "1. Choice of ML model : Supervised ML -> classsification -> Test + Training + Prediction \n",
    "2. Sentiment analysis :\n",
    "3. train and test supervised model\n",
    "4. Plotting ML model and comparing their performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23346b7f",
   "metadata": {},
   "source": [
    "## Choice of ML Model : Supervised ML and Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7729e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As reminder available dataframe : cap_df : EU\n",
    "cap_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0420b7a3",
   "metadata": {},
   "source": [
    "## Classification and Classification Rule\n",
    "#We are in classification situation we will then add a new column to classify the result \n",
    "#We apply the following rule to classify the Cap_coefficient as Good, Bad\n",
    "#Performance_score = Production_value / Total_amount \n",
    "1. If Performance_score > Cap_coefficent -> is Good\n",
    "2. If Perfromance_score < Cap_coefficeient -> is Bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6e8dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's create Performance_score to measure the performance\n",
    "cap_df['Performance_score'] = cap_df['Production_value']/cap_df['Total_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddcd537",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1205312",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b8ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's create then the Performance Class\n",
    "cap_df['Performance_class'] = np.where(cap_df.Performance_score > cap_df.Cap_coefficient, \"Good\", \"Bad\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726399e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_df.head(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67027aa6",
   "metadata": {},
   "source": [
    "Our Conclusion : We can see here that Based on our classification criteria for the last 3 years, Ireland is performing well against Spain and France. Cap coefficient seems to be not enough performing in France and Spain or those country.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caac034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the distribution of our classification\n",
    "cap_df['Performance_class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87db670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to explore our training and test we need to convert string x attributes in a scaler.\n",
    "# This include Entity, Performance_class\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "cap_df['Entity'] = le.fit_transform(cap_df['Entity'])\n",
    "cap_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ee0647",
   "metadata": {},
   "source": [
    "## TEST - TRAINING  - PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91981dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading sklearn libraries \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "    \n",
    "#loading our features to X and in y our target value\n",
    "X = cap_df.drop(['Performance_class'], axis=1)\n",
    "y = cap_df['Performance_class']\n",
    "\n",
    "#Split the data into 70% and 30% by using a parameter test_size = 30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "# Display the size of the rows and columns\n",
    "X.shape, y.shape, X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed500b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see here our distribution of 70% and 30% between training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5cf98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the logistic regression algorythm\n",
    "logreg = OneVsRestClassifier(LogisticRegression())\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3e2fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's do prediction for the test value provided\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df1f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's evaluate our model, we will use classification report for that\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d50896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can check also the accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e02ac2f",
   "metadata": {},
   "source": [
    "Our Conclusion : Accuracy score is at the highest level.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ae5b39",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132ca589",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Cross Validation \n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv_score_logistic_reg = cross_val_score(LogisticRegression(max_iter=1000),X,y,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a47ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv_score_logistic_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce22941",
   "metadata": {},
   "source": [
    "Our Conclusion : Cross validation validates our model at its highest level and percentage with 5 false."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c57f77",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b97c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying GrydSearchCv Method to find the best \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084bdc9e",
   "metadata": {},
   "source": [
    "## SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b98b12e",
   "metadata": {},
   "source": [
    "### Meat Supply Balance 2021\n",
    "source data :  https://www.cso.ie/en/releasesandpublications/ep/p-msb/meatsupplybalance2021/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a93fe5",
   "metadata": {},
   "source": [
    "#### PRE - PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f1b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import requests library in order to load the data directly from the server.\n",
    "#import BeautifilSoup to parse our data\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url_source = 'https://www.cso.ie/en/releasesandpublications/ep/p-msb/meatsupplybalance2021/'\n",
    "get_url = requests.get(url_source) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb51461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the connection with hosting server. 200 Required to confirm that the connection is made.\n",
    "print(get_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c87154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data with BeautifulSoup  \n",
    "stream = BeautifulSoup(get_url.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3de95f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check type of stream\n",
    "type(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dac821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the lenght\n",
    "len(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646002b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting text in an array\n",
    "page_text = stream.text\n",
    "print(page_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b82a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the type of page_text \n",
    "type(page_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795b3114",
   "metadata": {},
   "source": [
    "#### NLP PROCESSING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15512e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Necessary library for NLP\n",
    "import os\n",
    "import nltk\n",
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cbabdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Donwloading required library data\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff05b809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization of the content available in page_text\n",
    "from nltk.tokenize import word_tokenize\n",
    "ai_tokens = word_tokenize(page_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04024033",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick overview of our tokenization\n",
    "ai_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d121765",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the number of tokens we have\n",
    "len(ai_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab9d845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardisation of the text to limit the tokenization number\n",
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c281261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequency count for unique word \n",
    "for word in ai_tokens :\n",
    "    fdist[word.lower()]+=1\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3292d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check of Number of unqiue word \n",
    "len(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1605b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we want to see the top twenty words used here\n",
    "fdist_top10 = fdist.most_common(20)\n",
    "fdist_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f074839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stop words because they are not helping us for the analysis\n",
    "import re\n",
    "punctuation = re.compile(r'[-.?!,:;()|0-9]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a12a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_punctuation=[]\n",
    "for words in ai_tokens:\n",
    "    word = punctuation.sub(\"\",words)\n",
    "    if len(word)>0 :\n",
    "        post_punctuation.append(word)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1577df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a20a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the lenght after removing punctuation\n",
    "len(post_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cc9f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## POS ## Part of Speech and tagging words after in post punctuation\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a3c04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in post_punctuation:\n",
    "    print(nltk.pos_tag([token]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539f3145",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NER ## Named Entity Recognition and Classification\n",
    "from nltk import ne_chunk\n",
    "NE_tag = nltk.pos_tag([post_punctuation]))\n",
    "NE_ner = ne_chunk(NE_tag)\n",
    "print(NE_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4c2b45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
